{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "003aa42e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alexm\\AppData\\Local\\Temp\\ipykernel_4208\\4247761149.py:10: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(r'C:\\Users\\alexm\\FX_project\\2000_2024\\data2.csv')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5183 entries, 0 to 5182\n",
      "Data columns (total 63 columns):\n",
      " #   Column           Non-Null Count  Dtype         \n",
      "---  ------           --------------  -----         \n",
      " 0   DateID           5183 non-null   int64         \n",
      " 1   Date             5183 non-null   datetime64[ns]\n",
      " 2   Day              5183 non-null   float64       \n",
      " 3   Month            5183 non-null   float64       \n",
      " 4   Year             5183 non-null   float64       \n",
      " 5   Close_Mid        5183 non-null   float64       \n",
      " 6   Volume_Bid       5183 non-null   float64       \n",
      " 7   Volume_Ask       5183 non-null   float64       \n",
      " 8   Volume_Tot       5183 non-null   float64       \n",
      " 9   Close_Sprd       5183 non-null   float64       \n",
      " 10  5D-MA            5183 non-null   float64       \n",
      " 11  10D-MA           5183 non-null   float64       \n",
      " 12  20D-MA           5183 non-null   float64       \n",
      " 13  50D-MA           5183 non-null   float64       \n",
      " 14  200D-MA          5183 non-null   float64       \n",
      " 15  5D-Vol           5183 non-null   float64       \n",
      " 16  10D-Vol          5183 non-null   float64       \n",
      " 17  20D-Vol          5183 non-null   float64       \n",
      " 18  50D-Vol          5183 non-null   float64       \n",
      " 19  200D-Vol         5183 non-null   float64       \n",
      " 20  5D-ATR           5183 non-null   float64       \n",
      " 21  10D-ATR          5183 non-null   float64       \n",
      " 22  20D-ATR          5183 non-null   float64       \n",
      " 23  50D-ATR          5183 non-null   float64       \n",
      " 24  200D-ATR         5183 non-null   float64       \n",
      " 25  5D-ADX           5183 non-null   float64       \n",
      " 26  10D-ADX          5183 non-null   float64       \n",
      " 27  DIF              5183 non-null   float64       \n",
      " 28  DEA              5183 non-null   float64       \n",
      " 29  MACD             5183 non-null   float64       \n",
      " 30  14D-RSI          5183 non-null   float64       \n",
      " 31  StochOsc         5183 non-null   float64       \n",
      " 32  20D-Bol-Center   5183 non-null   float64       \n",
      " 33  20D-Bol-High     5183 non-null   float64       \n",
      " 34  20D-Bol-Low      5183 non-null   float64       \n",
      " 35  US-BaseRate      5183 non-null   float64       \n",
      " 36  UK-BaseRate      5183 non-null   float64       \n",
      " 37  US-5Y-Inf        5183 non-null   float64       \n",
      " 38  UK-5Y-Inf        5183 non-null   float64       \n",
      " 39  US-2Y-Int        5183 non-null   float64       \n",
      " 40  US-10Y-Int       5183 non-null   float64       \n",
      " 41  UK-2Y-Int        5183 non-null   float64       \n",
      " 42  UK-10Y-Int       5183 non-null   float64       \n",
      " 43  US-RealGDP       5183 non-null   float64       \n",
      " 44  US-NomGDP        5183 non-null   float64       \n",
      " 45  US-DispInc       5183 non-null   float64       \n",
      " 46  US-NomDispInc    5183 non-null   float64       \n",
      " 47  US-Unemp         5183 non-null   float64       \n",
      " 48  US-CPI           5183 non-null   float64       \n",
      " 49  US-HousePrice    5183 non-null   float64       \n",
      " 50  US-CommmRealEst  5183 non-null   float64       \n",
      " 51  US-MktVol        5183 non-null   float64       \n",
      " 52  UK-RealGDP       5183 non-null   float64       \n",
      " 53  UK-NomGDP        5183 non-null   float64       \n",
      " 54  UK-CPI           5183 non-null   float64       \n",
      " 55  UK-Unemp         5183 non-null   float64       \n",
      " 56  UK-CorpProf      5183 non-null   float64       \n",
      " 57  UK-HshldInc      5183 non-null   float64       \n",
      " 58  UK-ResPropInc    5183 non-null   float64       \n",
      " 59  UK-SecLend       5183 non-null   float64       \n",
      " 60  UK-ConsCred      5183 non-null   float64       \n",
      " 61  UK-RetailVol     5183 non-null   float64       \n",
      " 62  UK-MktVol        5183 non-null   float64       \n",
      "dtypes: datetime64[ns](1), float64(61), int64(1)\n",
      "memory usage: 2.5 MB\n"
     ]
    }
   ],
   "source": [
    "# download the dataset and normalise\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#load the consolidated dataset\n",
    "df = pd.read_csv(r'C:\\Users\\alexm\\FX_project\\2000_2024\\data2.csv')\n",
    "\n",
    "# remove extra rows and columns\n",
    "df = df.iloc[200:5383, 0:62]\n",
    "\n",
    "# reformat Local time variable as a datetime\n",
    "from datetime import datetime\n",
    "\n",
    "df['Date'] = df['Date'].str[6:10] +'-'+ df['Date'].str[3:5] +'-'+ df['Date'].str[0:2]\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "# normalise data\n",
    "\n",
    "df_norm = df.iloc[:, 5:]\n",
    "df_dates = df.iloc[:, :5]\n",
    "\n",
    "for col in df_norm.columns:\n",
    "    df_norm[col] = (df_norm[col] - df_norm[col].mean())/ df_norm[col].std()\n",
    "\n",
    "x = df_norm.to_numpy()\n",
    "y = df_dates.to_numpy()\n",
    "cols = df.columns\n",
    "z = np.append(y,x, axis=1)\n",
    "\n",
    "df_norm2 = pd.DataFrame(z, columns=cols)\n",
    "\n",
    "# add an integer series to replace date for use in the ANN\n",
    "df_norm2['DateID'] = range(df_norm2.shape[0])\n",
    "first_column = df_norm2.pop('DateID') \n",
    "df_norm2.insert(0, 'DateID', first_column)\n",
    "\n",
    "df_norm2.iloc[:,2:] = df_norm2.iloc[:,2:].astype(float)\n",
    "\n",
    "df_norm2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "99bb2028",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1.879571\n",
       "1    1.880129\n",
       "2    1.878323\n",
       "3    1.874248\n",
       "4    1.869645\n",
       "Name: Mean, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for stationarity of mean and variance. Two options:\n",
    "\n",
    "# 1. track variance across sub time-series\n",
    "df_ts = df_norm2['Close_Mid']\n",
    "\n",
    "n = 10\n",
    "m = 5\n",
    "\n",
    "# create an empty list to contain the time series\n",
    "series = []\n",
    "\n",
    "# create elements of this list that are n + m series starting and time = 0, then time = 1 etc.\n",
    "for i in range(len(df_ts) - n - m +1):\n",
    "    series.append(df_ts[i:i+n+m])\n",
    "\n",
    "# convert series to an array\n",
    "series = np.array(series)\n",
    "\n",
    "# calculate mean and variance of each time series\n",
    "cols = ['t0', 't1', 't2', 't3', 't4', 't5', 't6', 't7', 't8', 't9', 't10', 't11', 't12', 't13', 't14']\n",
    "\n",
    "df_series = pd.DataFrame(series, columns=cols)\n",
    "df_series['Variance'] = df_series.var(axis=1)\n",
    "df_series['Mean'] = df_series[['t0', 't1', 't2', 't3', 't4', 't5', 't6', 't7', 't8', 't9', 't10', 't11', 't12', 't13', 't14']].mean(axis=1)\n",
    "\n",
    "# export to view in Excel\n",
    "df_series.to_csv('data_varCheck_v3.csv')\n",
    "\n",
    "df_series['Mean'].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ff6bedd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADF Statistic: -1.519318\n",
      "p-value: 0.523934\n",
      "Lags used: 1.000000\n",
      "Observations: 5181.000000\n",
      "Critical Values:\n",
      "\t1%: -3.432\n",
      "\t5%: -2.862\n",
      "\t10%: -2.567\n",
      "Info criterion: -33943.044711\n",
      "\n",
      "KPSS Statistic: 9.674500\n",
      "p-value: 0.010000\n",
      "Lags: 1.000000\n",
      "Critical Values:\n",
      "\t10%: 0.347\n",
      "\t5%: 0.463\n",
      "\t2.5%: 0.574\n",
      "\t1%: 0.739\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alexm\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\stattools.py:2018: InterpolationWarning: The test statistic is outside of the range of p-values available in the\n",
      "look-up table. The actual p-value is smaller than the p-value returned.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsmodels.tsa.stattools import adfuller, kpss\n",
    "\n",
    "X = df_norm2.values[:,5]\n",
    "\n",
    "# 2. apply the Augmented Dickey-Fuller (ADF) test\n",
    "# https://machinelearningmastery.com/time-series-data-stationary-python/\n",
    "\n",
    "result_adf = adfuller(X)\n",
    "print('ADF Statistic: %f' % result_adf[0])\n",
    "print('p-value: %f' % result_adf[1])\n",
    "print('Lags used: %f' % result_adf[2])\n",
    "print('Observations: %f' % result_adf[3])\n",
    "print('Critical Values:')\n",
    "for key, value in result_adf[4].items():\n",
    "    print('\\t%s: %.3f' % (key, value))\n",
    "print('Info criterion: %f' % result_adf[5])\n",
    "\n",
    "# p statistic of 0.52 indicates the dataset is non-stationary so we expect some time dependency in the means and variances\n",
    "# that can possibly be learned. The moving mean or variance dynamic is expected from my knowledge of FX option pricing\n",
    "\n",
    "\n",
    "# 3. apply the Kwiatkowski-Phillips-Schmidt-Shin (KPSS) test\n",
    "\n",
    "result_kpss = kpss(X)\n",
    "print('\\nKPSS Statistic: %f' % result_kpss[0])\n",
    "print('p-value: %f' % result_kpss[1])\n",
    "print('Lags: %f' % result_adf[2])\n",
    "print('Critical Values:')\n",
    "for key, value in result_kpss[3].items():\n",
    "    print('\\t%s: %.3f' % (key, value))\n",
    "    \n",
    "# KPSS p-value of 0.01 (small) indicates that the series is non-stationary but not to a very significant level\n",
    "# KPSS looks for trends. This result indicates there is a trend\n",
    "# https://www.machinelearningplus.com/time-series/kpss-test-for-stationarity/?utm_content=cmp-true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a90e0b63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb790a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
